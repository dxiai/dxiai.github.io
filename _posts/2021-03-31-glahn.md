---
layout: post
title: Normalität und gerundete Werte
author: Christian Glahn
date: 2021-03-31
tags: 
- statistik
- praxis
- normalverteilung
- stichproben
- homogenität
---

Die Normalverteilung ist für die Statistik zentral und viele statistische Methoden setzen voraus, dass die Daten normalverteilt sind. Entsprechend müssen wir immer wieder die Frage beantworten, ob unsere Daten auch hinreichend normalverteilt sind. Diese Frage ist nicht neu und es gibt verschiedene und gut gesicherte Verfahren, um sie zu beantworten. Eine andere nicht so oft gesstellte Frage ist, ob unsere Daten überhaupt geeignet sind, um die Normalverteilung statistisch überprüfen zu können. Konkret geht es um die Überprüfung der Normalverteilung, wenn unsere Daten gerundet wurden *und* unsere Daten sehr homogen sind. 

Dazu erinnern wir uns an unsere Statistikeinführung. Dort haben wir sicher gelernt, dass wir nominal-, ordinal- und metrischskalierte Variablen unterscheinden und dass die Normalverteilung nur für metrischskalierte Variablen möglich ist. 

Damit wir diesen Beitrag nachvollziehen können, erinnern wir uns noch, dass wir die Werte von ordinalskalierten Variablen zwar sortieren können aber die Abstände zwischen den Werte unbekannt sind, weil wir nur bestimmte Were erhalten. Solche Variablen werden auch als *diskret* bezeichnet. Als Beispiel kann uns ein Küchenherd dienen: Bei vielen Elektroherden können wir die Hitze der Kochplatten oder -Felder mit einem Regler steuern. Bei meinem Herd gibt es dafür 10 Stufen von 0 bis 9. Ich kann nur die Stufen 0, 1, 2, 3, 4, 5, 6, 7, 8 und 9 auswählen. Ich weiss zwar, dass 8 heisser als 7 und weniger heiss als 9 ist, aber ich kann nicht beurteilen, ob die Temperaturdifferenz auf den Stufen 7, 8 und 9 immer gleich ist. Bei meinem Herd kann ich auch keine halben oder viertel Stufen einstellen. 

Im Vergleich dazu ist eine metrischskalierte Variable mit einem Gasherd vergleichbar, bei dem wir stufenlos die Hitze einstellen können. Wenn das Stellrad ein gleichmässiges Gewinde hat, dann entspricht eine halbe Umdrehung des Gashahns immer den gleichen Zuwachs Gas und damit mehr Hitze. Zusätzlich können wir die Umdrehungen nach belieben abstufen, wenn wir etwas weniger Hitz haben wollen. Diese Eigenschaften finden wir auch bei anderen Arten von Daten: Geld ist oft metrischskaliert, Entfernungen sind metrischskaliert und auch die Zeit ist metrischskaliert. 

Nun gibt es Daten, die grundsätzlich metrischskaliert sind. Nehmen wir die z.B. Zeit. In der Praxis werden wir aber über bestimmte Zeitintervalle nicht als kontinuierliches Spektrum reden, sondern nur in gerundeten Werten. Ein Beispiel ist das Alter einer Person. Obwohl das Alter ein kontinuerlicher Zeitraum von der Geburt bis heute ist, sagt praktisch niemand, dass eine Person `39.5678` Jahre alt sei. Vielmehr runden wir diesen Wert zum letzten ganzen Jahr *ab* und stellen fest, dass die Person `39` Jahre alt ist. 

Wir würden erwarten, dass ein solches abrunden keinen gewaltigen Effekt auf die Verteilung einer beliebigen Gruppe von Personen hat. Das können wir mit R leicht überprüfen. 


Dazu erstellen wir uns eine Stichprobe mit normalverteilten Werten um den Mittelwert `30` und einer Standardabweichung von `20`.


```R
daten = tibble(o_x = rnorm(101, mean = 30, sd = 20)) 
```

Anschliessend runden wir die Werte und behalten sowohl den originalen als auch den gerundeten Wert. Das Ganze visualisieren wir  mit [ggplot2](https://ggplot2-book.org) als gegenübergestellte Histogramme.


```R
daten %>%
    mutate(r_x = round(o_x)) -> daten_gerundet

daten_gerundet %>%
    pivot_longer(everything(), names_to = "nm", values_to = "vl") %>%
    ggplot(aes(vl)) +
        geom_histogram(aes(y = ..density..), fill = "white", color = "black" ) +
        geom_line(stat = "function", 
                  fun = dnorm, args= c(mean = 30, sd = 20), color = "red") +
        facet_wrap(vars(nm))
```

    `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
    



    
![png](/assets/images/post_20210331/output_6_1.png)
    


Man erkennt leicht, dass sich die beiden Histogramme für die originalen und gerundeten Werte kaum unterscheiden. Das ist auch nicht weiter verwirrend, da es sich ja die gleichen Werte handelt. Der einzige Unterschied liegt darin, dass das rechte Histogramm die gerundeten Werte berücksichtigt. 

Im Histogramm habe ich die Normalverteilung als rote Linie mit eingezeichnet, um die Ähnlichkeit hervorzuheben.

Wir können die Normalität unserer Daten zusätzlich mit anderen Techniken verifizieren. Rein statistisch geht das z.B. mit dem [Shapiro-Wilk-Test]().


```R
daten_gerundet %>% 
    summarise(
        o_swt = shapiro.test(o_x) %>% pluck("p.value"),
        r_swt = shapiro.test(r_x) %>% pluck("p.value")
    )
```


<table>
<thead>
	<tr><th scope=col>o_swt</th><th scope=col>r_swt</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0.8076272</td><td>0.7415109</td></tr>
</tbody>
</table>



In beiden Fällen liefert der *Shapiro-Wilk-Test* eine hohe Wahrscheinlichkeit, dass beide Verteilungen der Normalverteilung ähneln. Das ist was wir erwarten würden. 

Zusätzlich schauen wir uns noch den Quantile-Plot für unsere Verteilungen an.


```R
daten_gerundet %>%
    pivot_longer(everything(), names_to = "nm", values_to = "vl") %>%
    ggplot(aes(sample = vl)) +
        geom_qq() +
        geom_qq_line() +
        facet_wrap(vars(nm))
```


    
![png](/assets/images/post_20210331/output_10_0.png)
    


Der Quantile-Plot zeigt schön, dass unsere werte sehr nah an der theoretisch erwarteten Line der Normalverteilung liegen. Genau das habe ich auch erwartet.

Wir sehen sowohl im Shapiro-Wilk-Test und im Quantile-Plot, dass das Runden von Werten einer metrischenskalierten Variable kaum Auswirkungen auf die Einschätzung für eine Normalverteilung hat.

Leider gibt es im Alltag immer wieder Situationen, in denen diese Aussage nicht ganz zutrifft. Praktisch relevant ist das für homogene Stichproben. 

Wir erinnern uns an den Statistikunterricht, *homogene Stichproben sind Stichproben in denen eines oder mehrere Merkmale nur sehr wenig gestreut sind*. Mit anderen Worten, die Standardabweichung (oder die Mittlere Abweichung vom Median) ist klein. Mit klein meine ich Standardabweichungen die kleiner sind als z.B. `5` sind. Das ist kein absoluter Wert, sondern hängt von der Rundung ab: Wenn ich auf eine Nachkommastelle gerundet hätte, dann würde sich *klein* um Faktor 10 verringern, also z.B. auf `0.5`. 

Das Veranschaulichen wir uns an der Gruppe der Studienanfängern im 1. Semester. Diese Gruppe ist im Verhältnis zu allen Studierenden im gleichen Studiengang (oder der Hochschule) bezüglich des Alters sehr homogen. Die Standardabweichung liegt dabei in der Regel um 3 Jahren.

Wiederholen wir unser Experiement mit einer ähnlichen Stichprobe. 


```R
tibble(o_x = rnorm(101, mean = 25, sd = 3)) %>%
    mutate(
        r_x = round(o_x)
    ) -> daten_homogen
```


```R
daten_homogen %>%
    pivot_longer(everything(), names_to = "namen", values_to = "werte") %>%
    ggplot(aes(werte)) +
        geom_histogram(aes(y = ..density..), binwidth = 1,
                       fill = "white", color = "black" ) +
        geom_line(stat = "function", 
                  fun = dnorm, args= c(mean = 25, sd = 3), color = "red") +
        facet_wrap(vars(namen))
```


    
![png](/assets/images/post_20210331/output_13_0.png)
    


Die beiden Verteilungen sehen eigentlich gut aus und ich würden keine Unterschiede bezüglich der Normalverteilung erwarten. Das prüfe ich mit dem Shapiro-Wilk-Test. 


```R
daten_homogen %>% 
    summarise(
        o_swt = shapiro.test(o_x) %>% pluck("p.value"),
        r_swt = shapiro.test(r_x) %>% pluck("p.value")
    )
```


<table>
<thead>
	<tr><th scope=col>o_swt</th><th scope=col>r_swt</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0.1863778</td><td>0.03313807</td></tr>
</tbody>
</table>



Hier sehen wir einen deutlichen Unterschied zwischen den beiden Verteilungen. Die gerundeten Werte werden nur noch gerade noch so als Normalverteilt erkannt.

Betrachten wir also auch den Quantile-Plot für meine Daten:


```R
daten_homogen %>%
    pivot_longer(everything(), names_to = "namen", values_to = "werte") %>%
    ggplot(aes(sample = werte)) +
        geom_qq() +
        geom_qq_line() +
        facet_wrap(vars(namen))
```


    
![png](/assets/images/post_20210331/output_17_0.png)
    


In diesen Daten sehen wir für die gerundeten Daten zwar noch eine deutliche nähe zu der Theoretischen Verteilung. Die Daten liegen aber nicht wie die originalen Werte an der Linie, sondern verlaufen irgendwie quer zur theoretischen Vorhersage.

Dieses Bild ist nicht völlig unerwartet, weil die gerundeten Daten nur bestimmte Werte annehmen können. Ein solches Bild ist übrigens typisch für ordinalskalierte Daten. 

Dramatisch wird es, wenn eine grössere Stichprobe vorliegt. Für grössere Stichproben würden wir uns normalerweise eine bessere Passung unserer Daten erwarten. 


```R
tibble(o_x = rnorm(301, mean = 25, sd = 3)) %>%
    mutate(
        r_x = round(o_x)
    ) %>%
    summarise(
        o_swt = shapiro.test(o_x) %>% pluck("p.value") ,
        r_swt = shapiro.test(r_x) %>% pluck("p.value") 
    )
```


<table>
<thead>
	<tr><th scope=col>o_swt</th><th scope=col>r_swt</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>0.4773816</td><td>0.00797515</td></tr>
</tbody>
</table>



Unsere originalen Daten sind weiterhin klar normalverteilt. Für die gerundeten Daten müsste ich aber wegen des Shapiro-Wilk-Tests die Normalverteilung ablehnen. 

Das Ergebnis kann natürlich nur ein einmaliges konstruiertes Ereignis sein. Damit wir die Beobachtung Verallgemeinern können, brauchen wir mehr Beobachtungen. 

Dazu mache ich ein grösseres Experiment. Ich erzeuge jeweils 100 Stichproben mit dem Umfang von 100 sowie 300 Werten für die Standardabweichungen zwischen 1 bis 7. Der Mittelwert ist egal, daher nehme ich den Konstanten Wert von 25 um Durchschnittliche FH Studierende zu im 1. oder 2. Semester zu simulieren. Jede dieser Stichproben erzeuge ich wie die Beispielstichprobe von oben mit `tibble(d = rnorm(n, mean = 25, sd = v)`, wobei `n` der Stichprobenumfang und `v` die Varianz der Stichprobe ist. Damit ich die Werte paarweise vergleichen kann, runde ich die Ergebnisse wie oben. Anschliessend führe ich den Shapiro-Wilk-Test für die originalen und die gerundeten Werte in jeder der erzeugten Stichproben durch. 


```R
simds = tibble(sz = c(100, 300)) %>%
    expand(sz, sd = seq(1, 7)) %>% 
    mutate(
        ds = map2(sz, sd, (function(n, v) 
                seq(1, 100)  %>% map((function(m)
                        tibble(d = rnorm(n, mean = 25, sd = v)) %>%
                            mutate(
                                dr = round(d)
                            ) %>%
                            summarise(
                                swt_orig = shapiro.test(d) %>% pluck("p.value"),
                                swt_rund = shapiro.test(dr) %>% pluck("p.value")
                            )
                         ) 
                    )
            )
        ),
        ll = lengths(ds),
        swt_orig = ds %>% map(function(d) d %>% map(pull,var = "swt_orig")), 
        swt_rund = ds %>% map(function(d) d %>% map(pull,var = "swt_rund"))
    ) 
```

Jetzt habe ich 2800 Stichproben Shapiro-Wilk-Tests für 1400 Zufallsstichproben durchgeführt. Für jede der Stichproben habe ich den Shapiro-Wilk-Test jeweils für die ungerundeten und die gerundeten Werte berechnet. Damit stelle ich die Vergleichbarkeit unserer Ergebnisse durchgängig sicher, denn wir wissen, dass für jeden *p-Wert* für gerundete Werte ein *p-Wert* für ungerundete Werte gehört.

Meine ersten Beobachtungen lassen zwei mögliche Hypothesen zu.

1. Der Shapiro-Wilk-Test bestätigt für gerundete Werte die Normalverteilung immer seltener als für ungerundete Werte.
1. Der Shapiro-Wilk-Test bestätigt die Normalverteilung für gerundete und ungerundete Werte gleich häufig.

Diese Hypothesen kann ich mit den simulierten Ergebnissen überprüfen. Weil ich Zufallsstichproben erstellt habe, werden die Ergebnisse mehr oder weniger normalverteilt um die häufigsten Werte für den Shapiro-Wilk-Test für eine bestimmte Standardabweichung liegen. Also berechne ich den Mittelwert und die Standardabweichung für die einzelnen Stichprobengruppen. Die Funktion `map_dbl` erledigt den Grossteil des Jobs für uns. Die innere Funktion, die ich an `map_dbl` übergebe, sorgt dafür, dass die Werte als Vektor an die jeweilige Funktion übergeben werden können. 

Neben den Lagemassen bestimme ich noch die Anzahl der Stichproben, die durch den Shapiro-Wilk-Test als hinreichend normalverteilt erkannt wurden. Diese Zahl bestimme ich jeweils für das 95%-Konfidenzintervall sowie wie für das strengere 90% Konfidenzintervall. 

Die Vektoren mit dem Abfang `o_` verweisen auf die Ergebnisse der ungerundeten Werte. Die Vektoren mit dem Anfang `r_` beziehen sich auf die gerundeten Werte. 


```R
simds %>% 
    select(-c(ds)) %>%
    mutate(
        o_mw = swt_orig %>% map_dbl(function(x) x %>% unlist %>% mean),
        o_sd = swt_orig %>% map_dbl(function(x) x %>% unlist %>% sd),
        o_n90 = swt_orig %>% map_dbl(function(x) ifelse(x %>% unlist > 0.1, 1, 0) %>% sum),
        o_n95 = swt_orig %>% map_dbl(function(x) ifelse(x %>% unlist > 0.05, 1, 0) %>% sum),
        r_mw = swt_rund %>% map_dbl(function(x) x %>% unlist %>% mean),
        r_sd = swt_rund %>% map_dbl(function(x) x %>% unlist %>% sd),
        r_n90 = swt_rund %>% map_dbl(function(x) ifelse(x %>% unlist > 0.1 , 1, 0) %>% sum),
        r_n95 = swt_rund %>% map_dbl(function(x) ifelse(x %>% unlist > 0.05 , 1, 0) %>% sum),
    ) %>%
    select(-starts_with("swt")) %>%
    arrange(sd) -> sim_res
```


```R
sim_res
```


<table>
<thead>
	<tr><th scope=col>sz</th><th scope=col>sd</th><th scope=col>ll</th><th scope=col>o_mw</th><th scope=col>o_sd</th><th scope=col>o_n90</th><th scope=col>o_n95</th><th scope=col>r_mw</th><th scope=col>r_sd</th><th scope=col>r_n90</th><th scope=col>r_n95</th></tr>
	<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>
</thead>
<tbody>
	<tr><td>100</td><td>1</td><td>100</td><td>0.5065447</td><td>0.2647259</td><td>92</td><td>96</td><td>1.732884e-05</td><td>3.181774e-05</td><td> 0</td><td> 0</td></tr>
	<tr><td>300</td><td>1</td><td>100</td><td>0.5104359</td><td>0.2966514</td><td>88</td><td>94</td><td>3.502068e-11</td><td>1.082381e-10</td><td> 0</td><td> 0</td></tr>
	<tr><td>100</td><td>2</td><td>100</td><td>0.5155653</td><td>0.2724566</td><td>93</td><td>97</td><td>2.249521e-02</td><td>2.380281e-02</td><td> 1</td><td>11</td></tr>
	<tr><td>300</td><td>2</td><td>100</td><td>0.5167756</td><td>0.2898001</td><td>90</td><td>96</td><td>6.545307e-05</td><td>6.713743e-05</td><td> 0</td><td> 0</td></tr>
	<tr><td>100</td><td>3</td><td>100</td><td>0.4983786</td><td>0.2908598</td><td>88</td><td>92</td><td>1.487559e-01</td><td>1.344941e-01</td><td>52</td><td>72</td></tr>
	<tr><td>300</td><td>3</td><td>100</td><td>0.4843589</td><td>0.3027010</td><td>91</td><td>98</td><td>8.191736e-03</td><td>8.473458e-03</td><td> 0</td><td> 0</td></tr>
	<tr><td>100</td><td>4</td><td>100</td><td>0.4656560</td><td>0.2824380</td><td>83</td><td>93</td><td>2.321351e-01</td><td>1.707667e-01</td><td>72</td><td>81</td></tr>
	<tr><td>300</td><td>4</td><td>100</td><td>0.4709896</td><td>0.2596782</td><td>93</td><td>97</td><td>4.809246e-02</td><td>3.953590e-02</td><td>12</td><td>36</td></tr>
	<tr><td>100</td><td>5</td><td>100</td><td>0.4876623</td><td>0.2907267</td><td>90</td><td>96</td><td>3.200359e-01</td><td>2.318128e-01</td><td>81</td><td>89</td></tr>
	<tr><td>300</td><td>5</td><td>100</td><td>0.4763294</td><td>0.2973952</td><td>84</td><td>89</td><td>1.210158e-01</td><td>1.029215e-01</td><td>50</td><td>71</td></tr>
	<tr><td>100</td><td>6</td><td>100</td><td>0.4909743</td><td>0.2824142</td><td>93</td><td>95</td><td>3.658340e-01</td><td>2.465823e-01</td><td>85</td><td>95</td></tr>
	<tr><td>300</td><td>6</td><td>100</td><td>0.5016797</td><td>0.2806621</td><td>89</td><td>95</td><td>2.081683e-01</td><td>1.528467e-01</td><td>72</td><td>78</td></tr>
	<tr><td>100</td><td>7</td><td>100</td><td>0.5078396</td><td>0.2782365</td><td>90</td><td>95</td><td>4.127144e-01</td><td>2.579759e-01</td><td>88</td><td>92</td></tr>
	<tr><td>300</td><td>7</td><td>100</td><td>0.5193758</td><td>0.2883552</td><td>91</td><td>93</td><td>2.945605e-01</td><td>2.065937e-01</td><td>83</td><td>90</td></tr>
</tbody>
</table>



Die Ergebnisse zeigen deutlich, dass der beobachtete Effekt konsistent bei Variablen auftritt, wenn die Werte gerundet sind und die Standardabweichung "klein" ist. Mit wachsender Standardabweichung werden zunehmend mehr Stichproben als normalverteilt erkannt. Diesen Effekt können wir uns mit zwei Diagrammen visuell veranschaulichen. 

Stellen wir zuerst die Mittelwerte der Testergebnisse über die jeweilige Standardabweichung dar.


```R
sim_res %>%
    ggplot(aes(sd, o_mw)) +
        geom_point() +
        geom_point(aes(y = r_mw), color = "red") +
        scale_y_continuous(limits = c(0, .6), name = "Mittelwert") +
        scale_x_continuous(limits = c(1, 7), n.breaks = 7, name = "Standardabweichung Stichprobe") +
        geom_hline(yintercept = .1, linetype = "dashed") +
        facet_wrap(vars(sz))
```


    
![png](/assets/images/post_20210331/output_26_0.png)
    

Die schwarzen Punkte zeigen die mittleren Ergebnisse des Shapiro-Wilk-Tests der originalen Werte und die roten Punkte für die gerundeten Werte an. Die horizontale gestrichelte Linie zeigt das Signifikanzniveau ab dem wir eine Normalverteilung akzeptieren würden. Ich habe zusätzlich die beiden Stichprobenumfänge separat dargestellt, damit die Unterschiede mit wachsenden Stichprobenumfang erkennbar werden. 

Diese Abbildung zeigt deutlich, dass die Ergebnisse mit grösserer Standardabweichung insgesamt zutreffende Ergebnisse liefern. Diese Gegenüberstellung zeigt uns allerdings nicht, wie viele dieser normalverteilten Stichproben wir als hinreichend normalverteilt akzeptiert hätten. Zu diesem Zweck erstelle ich ein zweites Diagramm und stellen die Anzahl der als hinreichend normalverteilt erkannten Stichproben dar. 


```R
sim_res %>%
    ungroup() %>%
    ggplot(aes(sd, o_n95)) +
        geom_point() +
        geom_point(aes(y = r_n95), color = "red") +
        scale_y_continuous(limits = c(0, 100), name = "Erkannte Stichproben") +
        scale_x_continuous(limits = c(1, 7), n.breaks = 7, name = "Standardabweichung Stichprobe") +
        facet_wrap(vars(sz))
```


    
![png](/assets/images/post_20210331/output_28_0.png)


Diese Darstellung zeigt schön, dass wir nicht die perfekte Normalverteilung erkennen müssen, um eine Stichprobe noch als hinreichend normalverteilt zu erkennen. Vielmehr werden bei ungerundeten Werten fast alle Stichproben als hinreichend normalverteilt erkannt. Das Diagramm zeigt damit sehr schön, dass wir keine besonders grossen p-Wert erhalten müssen, um eine Stichprobe richtig zuzuordnen. 

Für die in Rot dargestellten gerundeten Werte erkennen wir, dass bei kleinen Standardabweichungen die Trefferquote sehr gering ist. Eine gute Trefferquote liegt im Bereich oberhalb ab 90% (bzw. 90 korrekt als normalverteilt erkannten Stichproben). Damit verwerfen wir nur 10% der Stichproben, die aus eigentlich normalverteilten Grundgesamtheiten stammen. Dieser Wert entspricht dem empfohlenen Signifikanzniveaus von 10% für diesen Test. Das 5%-Signifikanzniveau für diesen Test wird auch für Zufallsstichproben mit ungerundeten Werte kaum erreicht. 

Diese Abbildung veranschaulicht auch gut, dass der Shapiro-Wilk-Test für grössere Stichproben weniger zuverlässige Ergebnisse liefert: Bei Stichprobenumfängen von 100 werden bereits ab einer Standardabweichung von 4 fast die geleiche Anzahl von Stichproben mit gerundeten Werten erkannt, wie bei den ungerundeten. Bei einem Stichprobenumfang von 300, erhalten wir erst ab einer Standardabweichung von 6 ähnlich gute Treffgenauigkeiten für die gerundeten Werte wie für die ungerundeten. 

### Fazit

Wenn wir metrisch skalierte Variablen haben und unsere Stichprobe sehr homogen verteilt ist, dann müssen wir aufpassen, wenn die Werte gerundet vorliegen. In der oben gezeigten Simulation kennen wir die Grundgesamtheit und wissen, dass jede der 1400 Stichproben eigentlich normalverteilt ist. Trotzdem haben wir zufällige Schwankungen in den simulierten Verteilungen. Diese Schwankungen können so gross sein, dass eine Verteilung nicht mehr korrekt mit Hilfe des Shapiro-Wilk-Tests zugeordnet werden kann. Liegen die Werte auch noch gerundet vor und sind nicht breit genug gestreut, dann erscheinen die Daten aus Sicht des Tests als *diskret*. Weil für die Normalverteilung, nominal- und ordinalskalierte Skalenniveaus nicht zulässig sind, lehnt der Shapiro-Wilk-Test Verteilungen ab, die zu homogen sind.   

